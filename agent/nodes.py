import os
import subprocess
import uuid
from pathlib import Path
from typing import Dict, Any

from agent.state import AgentState
# IMPORT PARSER HERE
from agent.llm import fix_chain, parser 
from agent.rag import search_codebase 
from agent.context import get_code_snippet 

# --- CONFIGURATION ---
GCC_PATH = r"D:\eaton-ut\GCC-140200-64\GCC-140200-64\bin\gcc.exe"
if os.path.exists(GCC_PATH):
    os.environ["PATH"] += os.pathsep + str(Path(GCC_PATH).parent)

TESTCODE_DIR = Path("testcode").resolve()
# NOTE: We now build test.c AND math_utils.c together!
# Added -I"{TESTCODE_DIR}" so GCC finds your local headers!
BUILD_CMD = f'"{GCC_PATH}" "{TESTCODE_DIR / "test.c"}" "{TESTCODE_DIR / "math_utils.c"}" -I"{TESTCODE_DIR}" -o "{TESTCODE_DIR / "test_app"}" -Wall'

# --- NODE 1: CHECK WORKSPACE ---
def check_workspace_node(state: AgentState) -> Dict[str, Any]:
    res = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True)
    return {"workspace_clean": not bool(res.stdout.strip())}


# --- NODE 2: CREATE BRANCH ---
def create_branch_node(state: AgentState) -> Dict[str, Any]:
    branch_name = f"ai-fix-{uuid.uuid4().hex[:8]}"
    subprocess.run(["git", "checkout", "-b", branch_name], check=False)
    print(f"ðŸ›¡ï¸  Switched to branch: {branch_name}")
    return {"branch_name": branch_name}


# --- NODE 3: RUN BUILD ---
def run_build_node(state: AgentState) -> Dict[str, Any]:
    print("ðŸ”¨ Running build...")
    res = subprocess.run(BUILD_CMD, capture_output=True, text=True, shell=True)
    logs = res.stdout + "\n" + res.stderr
    
    errors = []
    warnings = []
    for line in logs.splitlines():
        if ": error:" in line or ": fatal error:" in line:
            errors.append(line.strip())
        elif ": warning:" in line:
            warnings.append(line.strip())
            
    success = (res.returncode == 0)
    print(f"Build Success: {success} | Errors: {len(errors)}")
    
    return {
        "build_success": success,
        "build_logs": logs,
        "error_lines": errors,
        "warning_lines": warnings
    }


# --- NODE 4: GATHER CONTEXT ---
def get_context_node(state: AgentState) -> Dict[str, Any]:
    """
    This node acts as the 'Information Gatherer' for the AI.
    It decides WHAT to fix (prioritizing errors over warnings) and 
    gathers the necessary code snippets (Local + RAG) so the AI can see the problem.
    """
    
    # --- 1. TRACKING RETRIES ---
    # Variable: current_retries
    # We read the current loop count from the state. If it's the first run, it defaults to 0.
    # This prevents the agent from looping infinitely if it gets stuck.
    current_retries = state.get("retry_count", 0)

    # --- 2. READING COMPILER OUTPUT ---
    # Variables: errors, warnings
    # We extract the lists of strings that were generated by the GCC build node.
    # Example: errors = ["test.c:10: error: missing ';'"]
    errors = state.get("error_lines", [])
    warnings = state.get("warning_lines", [])

    # --- 3. TARGET SELECTION (THE PRIORITY QUEUE) ---
    # The agent can only fix one thing at a time. We must pick a 'target_issue'.
    if errors:
        # Errors are fatal. If the 'errors' list is not empty, grab the very first one.
        target_issue = errors[0]
        issue_type = "ERROR"
    elif warnings:
        # If there are NO errors, but 'warnings' exist, we grab the first warning.
        # This allows the agent to clean up unused variables AFTER the code compiles.
        target_issue = warnings[0]
        issue_type = "WARNING"
    else:
        # Failsafe: If both lists are empty, there is nothing to fix. 
        # We return an empty update and keep the retry count exactly the same.
        return {"code_context": "", "current_issue": "", "retry_count": current_retries}

    # Print to the console so we know exactly what the agent is looking at
    print(f"ðŸ•µï¸  Reasoning about {issue_type}: {target_issue}")
    
    # --- 4. GATHERING LOCAL CONTEXT ---
    # Variable: local_context
    # We pass the target_issue (which contains the filename and line number) to our scraper.
    # It returns the exact line of code + 5 lines above and below it.
    local_context = get_code_snippet(target_issue, str(Path.cwd()))
    
    # --- 5. GATHERING RAG CONTEXT (PERIPHERAL VISION) ---
    # Variable: rag_context
    # We start with an empty string. We only use RAG if the error implies a missing file or function.
    rag_context = ""
    
    # Check if the GCC error text contains specific keywords related to missing definitions
    if "implicit declaration" in target_issue or "undefined reference" in target_issue:
        
        # Example target_issue: "implicit declaration of function 'add_numbers'"
        # We split the string by the single quote (') and grab the second item (index 1),
        # which isolates the function name: "add_numbers".
        query = target_issue.split("'")[1] if "'" in target_issue else ""
        
        if query:
            # We import the search tool here to query the Vector Database
            from agent.rag import search_codebase
            
            # Search the database for the isolated function name (e.g., "add_numbers")
            # We only ask for the top 1 most relevant result to save token space.
            results = search_codebase(query, n_results=1)
            
            if results:
                # If we found the function in another file, format it nicely into the rag_context string.
                rag_context = f"\n\n--- RAG SEARCH RESULT ---\n{results[0]['code']}\n"

    # --- 6. COMBINING CONTEXTS ---
    # Variable: full_context
    # We merge the local code snippet and the RAG search result (if any).
    # If no RAG search was triggered, it just adds an empty string.
    # CRITICAL: This line is flush with the main function block, outside the RAG 'if' statement.
    full_context = local_context + rag_context
    
    # --- 7. UPDATING THE STATE ---
    # We return a dictionary. LangGraph will take these keys and overwrite 
    # the corresponding keys in the global AgentState.
    return {
        "code_context": full_context,         # The combined code text for the LLM prompt
        "current_issue": target_issue,        # The specific error/warning we are fixing
        "retry_count": current_retries + 1    # Increment the loop counter by 1
    }
# --- NODE 5: GENERATE FIX (UPDATED!) ---
def generate_fix_node(state: AgentState) -> Dict[str, Any]:
    # LINE 1: Retrieve the exact issue (Error or Warning) we selected in the previous node.
    issue_msg = state.get("current_issue", "")
    
    # LINE 2: Retrieve the code blocks (Local + RAG) we gathered.
    context = state.get("code_context", "")
    
    print("ðŸ¤– AI is generating a fix...")
    try:
        # LINE 3 to 7: Trigger the LangChain LLM pipeline. 
        # We inject 'issue_msg' into the "error_msg" variable inside the prompt template.
        result = fix_chain.invoke({
            "error_msg": issue_msg, 
            "code_context": context,
            "format_instructions": parser.get_format_instructions()
        })
        
        # LINE 8 & 9: Extract the JSON list and update the state.
        fixes = result.get("fixes", [])
        return {"proposed_fixes": fixes}
    except Exception as e:
        print(f"ðŸ’¥ AI Generation Failed: {e}")
        return {"proposed_fixes": []}

# --- NODE 6: APPLY FIX ---
def apply_fix_node(state: AgentState) -> Dict[str, Any]:
    fixes = state.get("proposed_fixes", [])
    if not fixes:
        print("ðŸ¤· No fixes to apply.")
        return {}

    for fix in fixes:
        # LangChain's parser returns a dict
        file_path = fix['file']
        original = fix['original_code']
        replacement = fix['replacement_code']
        
        abs_path = Path(file_path).resolve()
        
        try:
            with open(abs_path, "r", encoding="utf-8") as f:
                content = f.read()
            
            # Normalize line endings just in case
            content_norm = content.replace("\r\n", "\n")
            original_norm = original.replace("\r\n", "\n")
            
            if original_norm in content_norm:
                new_content = content_norm.replace(original_norm, replacement)
                with open(abs_path, "w", encoding="utf-8") as f:
                    f.write(new_content)
                print(f"âœ… Applied fix to {abs_path.name}")
            else:
                print(f"âš ï¸ Fix Failed: Could not find original code block in {abs_path.name}")
                # Debug print to help you see what failed
                # print(f"Looking for:\n{original_norm!r}")
                
        except Exception as e:
            print(f"âŒ File Error: {e}")
            
    return {}


# --- NODE 7: REVERT ---
def revert_node(state: AgentState) -> Dict[str, Any]:
    branch = state["branch_name"]
    print(f"ðŸ”™ Reverting branch {branch}...")
    subprocess.run(["git", "checkout", "main"], capture_output=True)
    subprocess.run(["git", "branch", "-D", branch], capture_output=True)
    return {"workspace_clean": True}